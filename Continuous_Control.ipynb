{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ddpg_agent import Agent\n",
    "from collections import deque\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=r\"E:\\Udacity\\DeepReinforcementLearning\\deep-reinforcement-learning-master\\deep-reinforcement-learning-master\\p2_continuous-control\\Reacher_Windows_x86_64\\Reacher_Windows_x86_64\\Reacher.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "           \n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "count = 0\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    count = count + 1\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        print(count)\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the agent\n",
    "\n",
    "In the next code cell, we initialize the agent and train the agent with data we recieve from the the individual agents in the environment. Here we will gradually improve the performance of our agent to choose better actions when interacting with the environment.\n",
    "\n",
    "Once we have a received an average score of 30+ over the last 100 episodes, we break from the training algorithm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "Actor(\n",
      "  (fc1): Linear(in_features=33, out_features=400, bias=True)\n",
      "  (fc2): Linear(in_features=400, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=4, bias=True)\n",
      ")\n",
      "Critic(\n",
      "  (fcs1): Linear(in_features=33, out_features=400, bias=True)\n",
      "  (fc2): Linear(in_features=404, out_features=300, bias=True)\n",
      "  (fc3): Linear(in_features=300, out_features=1, bias=True)\n",
      ")\n",
      "Episode 10\tAverage Score: 0.75\n",
      "scores:  [0.53999999 0.59999999 0.73999998 0.18       2.93999993 0.51999999\n",
      " 0.57999999 0.74999998 1.48999997 1.41999997 0.79999998 0.54999999\n",
      " 1.46999997 2.18999995 0.32999999 2.45999995 1.27999997 0.94999998\n",
      " 2.41999995 1.38999997]\n",
      "Episode 20\tAverage Score: 1.08\n",
      "scores:  [2.72999994 2.25999995 0.97999998 1.13999997 1.89999996 2.04999995\n",
      " 2.51999994 2.17999995 1.77999996 1.24999997 0.84999998 1.92999996\n",
      " 0.92999998 2.76999994 0.88999998 0.32999999 0.49999999 1.24999997\n",
      " 1.06999998 1.01999998]\n",
      "Episode 30\tAverage Score: 2.30\n",
      "scores:  [8.16999982 8.68999981 6.33999986 7.77999983 7.26999984 3.29999993\n",
      " 6.84999985 8.55999981 6.19999986 6.46999986 7.76999983 8.05999982\n",
      " 4.5199999  5.23999988 7.45999983 5.98999987 6.32999986 7.60999983\n",
      " 8.55999981 9.93999978]\n",
      "Episode 40\tAverage Score: 3.79\n",
      "scores:  [ 5.72999987  7.40999983  9.54999979  8.8999998   7.13999984  9.56999979\n",
      "  5.82999987  9.98999978  5.61999987 10.11999977 10.68999976 11.22999975\n",
      "  8.02999982  9.69999978 11.34999975  7.12999984  6.48999985  5.47999988\n",
      "  8.11999982  9.17999979]\n",
      "Episode 50\tAverage Score: 4.97\n",
      "scores:  [10.60999976  9.60999979  6.41999986 10.43999977 13.98999969 14.76999967\n",
      "  9.85999978 10.94999976 12.51999972 14.93999967 15.44999965 11.24999975\n",
      " 16.46999963 11.89999973 13.85999969 17.23999961 12.47999972 13.14999971\n",
      "  9.1299998  15.47999965]\n",
      "Episode 60\tAverage Score: 6.76\n",
      "scores:  [27.69999938 16.45999963 23.33999948 19.04999957 15.97999964 19.54999956\n",
      " 12.65999972 22.4199995   8.14999982 12.88999971  7.41999983 23.49999947\n",
      " 20.56999954 13.4699997  13.5199997  18.40999959 18.38999959 24.23999946\n",
      " 21.70999951 19.51999956]\n",
      "Episode 70\tAverage Score: 9.51\n",
      "scores:  [31.2799993  28.61999936 32.82999927 31.3699993  35.08999922 28.27999937\n",
      " 27.62999938 29.39999934 33.12999926 27.19999939 34.70999922 29.24999935\n",
      " 30.58999932 24.46999945 24.56999945 35.7599992  22.3499995  28.71999936\n",
      " 30.53999932 29.95999933]\n",
      "Episode 80\tAverage Score: 12.62\n",
      "scores:  [33.56999925 26.10999942 37.65999916 36.80999918 36.37999919 34.17999924\n",
      " 36.73999918 36.32999919 37.73999916 32.97999926 38.17999915 33.54999925\n",
      " 36.16999919 38.35999914 36.74999918 39.44999912 37.99999915 39.14999912\n",
      " 37.68999916 36.09999919]\n",
      "Episode 90\tAverage Score: 15.30\n",
      "scores:  [39.24999912 37.47999916 37.32999917 38.01999915 37.59999916 36.23999919\n",
      " 38.13999915 37.85999915 39.18999912 36.99999917 30.03999933 39.33999912\n",
      " 35.9799992  39.53999912 36.76999918 36.27999919 38.69999913 38.07999915\n",
      " 38.46999914 39.08999913]\n",
      "Episode 100\tAverage Score: 17.43\n",
      "scores:  [35.46999921 35.6999992  38.68999914 36.63999918 29.13999935 33.24999926\n",
      " 38.64999914 36.38999919 31.92999929 27.96999937 36.74999918 29.10999935\n",
      " 37.68999916 35.26999921 32.46999927 37.69999916 38.04999915 38.44999914\n",
      " 35.24999921 34.59999923]\n",
      "Episode 110\tAverage Score: 20.99\n",
      "scores:  [36.64999918 36.13999919 33.45999925 32.52999927 39.41999912 35.25999921\n",
      " 26.16999942 38.66999914 39.09999913 35.05999922 35.6499992  38.49999914\n",
      " 32.54999927 35.45999921 36.45999919 37.49999916 38.06999915 36.81999918\n",
      " 33.02999926 26.02999942]\n",
      "Episode 120\tAverage Score: 24.46\n",
      "scores:  [38.64999914 37.79999916 37.49999916 36.78999918 38.03999915 35.26999921\n",
      " 35.9999992  39.35999912 38.36999914 37.02999917 36.50999918 39.46999912\n",
      " 36.26999919 37.06999917 37.55999916 35.5899992  37.78999916 38.52999914\n",
      " 32.00999928 32.53999927]\n",
      "Episode 130\tAverage Score: 27.67\n",
      "scores:  [37.16999917 38.13999915 35.9599992  36.07999919 36.54999918 33.95999924\n",
      " 33.28999926 37.90999915 37.76999916 37.43999916 31.86999929 38.56999914\n",
      " 37.71999916 36.97999917 37.16999917 37.50999916 38.70999913 36.90999917\n",
      " 36.36999919 37.37999916]\n",
      "Episode 139\tAverage Score: 30.21\n",
      "Goal reached in  139  episodes\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "agent = Agent(state_size, action_size, random_seed=0)\n",
    "print(agent.actor_local)\n",
    "print(agent.critic_local)\n",
    "def ddpg(n_episodes=200, max_t=1000, print_every=10):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_n = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        agent.reset()\n",
    "        scores = np.zeros(20)\n",
    "        for t in range(max_t):\n",
    "            actions = agent.act(states)\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "            rewards = env_info.rewards                         # get reward (for each agent)\n",
    "            dones = env_info.local_done                        # see if episode finished\n",
    "            agent.step(states, actions, rewards,  next_states, dones,t)\n",
    "            states = next_states \n",
    "            scores = scores + rewards                        # update the score (for each agent)\n",
    "\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        scores_deque.append(np.mean(scores))\n",
    "        scores_n.append(np.mean(scores))\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)), end=\"\")\n",
    "        torch.save(agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "        torch.save(agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "        if(np.mean(scores_deque) > 30.0):\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            print(\"Goal reached in \", i_episode, \" episodes\")\n",
    "            break\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_deque)))\n",
    "            \n",
    "    return scores_n\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Take Actions based on trained model\n",
    "\n",
    "In the next code cell, we will visualize the performance of our algorithm after we have completed the training.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001\n",
      "Total score (averaged over agents) this episode: 39.1269991254434\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(s_size, action_size, random_seed=0)\n",
    "# checkpoint = torch.load('checkpoint_actor.pth')\n",
    "agent.actor_local.load_state_dict(torch.load('checkpoint_actor.pth'))\n",
    "agent.critic_local.load_state_dict(torch.load('checkpoint_critic.pth')) \n",
    "agent.actor_local.eval()\n",
    "agent.critic_local.eval()\n",
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "count = 0\n",
    "while True:\n",
    "    actions = agent.act(states, False) # select an action (for each agent)\n",
    "                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    count = count + 1\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        print(count)\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
